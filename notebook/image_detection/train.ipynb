{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2c5098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e0dde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9afba6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54d3fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def print_folder_tree(start_path, prefix=\"\"):\n",
    "    items = [item for item in os.listdir(start_path) if os.path.isdir(os.path.join(start_path, item))]\n",
    "    pointers = ['├── '] * (len(items) - 1) + ['└── ']\n",
    "\n",
    "    for pointer, item in zip(pointers, items):\n",
    "        path = os.path.join(start_path, item)\n",
    "        print(prefix + pointer + item)\n",
    "        extension = '│   ' if pointer == '├── ' else '    '\n",
    "        print_folder_tree(path, prefix + extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a27e376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder structure of 'real_vs_ai_faces':\n",
      "├── dataset\n",
      "│   └── dataset\n",
      "│       ├── test\n",
      "│       │   ├── 0\n",
      "│       │   └── 1\n",
      "│       ├── train\n",
      "│       │   ├── 0\n",
      "│       │   └── 1\n",
      "│       └── validate\n",
      "│           ├── 0\n",
      "│           └── 1\n",
      "└── data_source\n",
      "    └── data_source\n",
      "        ├── fake\n",
      "        │   ├── faceswap\n",
      "        │   ├── sfhq\n",
      "        │   │   ├── pt1\n",
      "        │   │   ├── pt2\n",
      "        │   │   ├── pt3\n",
      "        │   │   └── pt4\n",
      "        │   ├── stable_diffusion\n",
      "        │   └── thispersondoesnotexist\n",
      "        └── ffhq\n",
      "\n",
      "Folder structure of '140k_faces':\n",
      "└── real_vs_fake\n",
      "    └── real-vs-fake\n",
      "        ├── test\n",
      "        │   ├── fake\n",
      "        │   └── real\n",
      "        ├── train\n",
      "        │   ├── fake\n",
      "        │   └── real\n",
      "        └── valid\n",
      "            ├── fake\n",
      "            └── real\n"
     ]
    }
   ],
   "source": [
    "print(\"Folder structure of 'real_vs_ai_faces':\")\n",
    "print_folder_tree(\"datasets/real_vs_ai_faces\")\n",
    "\n",
    "print(\"\\nFolder structure of '140k_faces':\")\n",
    "print_folder_tree(\"datasets/140k_faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fad190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae80fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_REAL_DIR = \"processed_dataset/real\"\n",
    "OUTPUT_FAKE_DIR = \"processed_dataset/fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8f04a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_REAL_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_FAKE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "955aacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DIRS = [\n",
    "    \"datasets/140k_faces/real_vs_fake/real-vs-fake/valid/real\",\n",
    "    \"datasets/140k_faces/real_vs_fake/real-vs-fake/valid/fake\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3fab5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_file(src_path, dst_folder):\n",
    "    filename = os.path.basename(src_path)\n",
    "    dst_path = os.path.join(dst_folder, filename)\n",
    "\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    counter = 1\n",
    "    while os.path.exists(dst_path):\n",
    "        dst_path = os.path.join(dst_folder, f\"{base}_{counter}{ext}\")\n",
    "        counter += 1\n",
    "\n",
    "    shutil.copy2(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "604d5f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder, class_type):\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Folder not found: {folder}\")\n",
    "        return\n",
    "\n",
    "    dst_folder = OUTPUT_REAL_DIR if class_type == \"real\" else OUTPUT_FAKE_DIR\n",
    "    images = [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        list(tqdm(executor.map(lambda img: copy_file(img, dst_folder), images),\n",
    "                  total=len(images),\n",
    "                  desc=f\"Copying {class_type} from {os.path.basename(folder)}\",\n",
    "                  unit=\"img\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "402daec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying real from real: 100%|██████████| 10000/10000 [00:09<00:00, 1024.59img/s]\n",
      "Copying real from fake: 100%|██████████| 10000/10000 [00:09<00:00, 1061.29img/s]\n"
     ]
    }
   ],
   "source": [
    "for folder in SOURCE_DIRS:\n",
    "    if \"real\" in folder:\n",
    "        process_folder(folder, \"real\")\n",
    "    elif \"fake\" in folder:\n",
    "        process_folder(folder, \"fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40c61df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_real = [\n",
    "    \"datasets/140k_faces/real_vs_fake/real-vs-fake/train/real\",\n",
    "    \"datasets/140k_faces/real_vs_fake/real-vs-fake/valid/real\",\n",
    "    \"datasets/140k_faces/real_vs_fake/real-vs-fake/test/real\"\n",
    "]\n",
    "dataset1_fake = [\n",
    "    \"datasets/140k_faces/real_vs_fake/real-vs-fake/train/fake\",\n",
    "    \"datasets/140k_faces/real_vs_fake/real-vs-fake/valid/fake\",\n",
    "    \"datasets/140k_faces/real_vs_fake/real-vs-fake/test/fake\"\n",
    "]\n",
    "\n",
    "dataset2_real = [\n",
    "    \"datasets/real_vs_ai_faces/dataset/dataset/train/0\",\n",
    "    \"datasets/real_vs_ai_faces/dataset/dataset/validate/0\",\n",
    "    \"datasets/real_vs_ai_faces/dataset/dataset/test/0\"\n",
    "]\n",
    "dataset2_fake = [\n",
    "    \"datasets/real_vs_ai_faces/dataset/dataset/train/1\",\n",
    "    \"datasets/real_vs_ai_faces/dataset/dataset/validate/1\",\n",
    "    \"datasets/real_vs_ai_faces/dataset/dataset/test/1\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f7281aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_REAL = \"processed_dataset/real\"\n",
    "OUTPUT_FAKE = \"processed_dataset/fake\"\n",
    "os.makedirs(OUTPUT_REAL, exist_ok=True)\n",
    "os.makedirs(OUTPUT_FAKE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "589800f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_from_folders(folders, dest_folder, prefix):\n",
    "    img_count = 0\n",
    "    for folder in folders:\n",
    "        label = os.path.basename(folder)  # real/fake\n",
    "        split = folder.split(\"/\")[-2]     # train/val/test\n",
    "        files = [f for f in os.listdir(folder) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "        for file in tqdm(files, desc=f\"Copying {label} from {split}\", unit=\"img\"):\n",
    "            src = os.path.join(folder, file)\n",
    "            new_name = f\"{prefix}_{split}_{img_count}_{file}\"\n",
    "            dst = os.path.join(dest_folder, new_name)\n",
    "            shutil.copy2(src, dst)\n",
    "            img_count += 1\n",
    "    print(f\"Copied {img_count} images to {dest_folder}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb706d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying real from train: 100%|██████████| 50000/50000 [04:34<00:00, 181.84img/s]\n",
      "Copying real from valid: 100%|██████████| 10000/10000 [00:56<00:00, 176.03img/s]\n",
      "Copying real from test: 100%|██████████| 10000/10000 [01:15<00:00, 131.87img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 70000 images to processed_dataset/real\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying fake from train: 100%|██████████| 50000/50000 [06:40<00:00, 124.89img/s]\n",
      "Copying fake from valid: 100%|██████████| 10000/10000 [01:09<00:00, 143.68img/s]\n",
      "Copying fake from test: 100%|██████████| 10000/10000 [01:28<00:00, 113.52img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 70000 images to processed_dataset/fake\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying 0 from train: 100%|██████████| 42000/42000 [06:09<00:00, 113.77img/s]\n",
      "Copying 0 from validate: 100%|██████████| 14000/14000 [02:24<00:00, 97.18img/s] \n",
      "Copying 0 from test: 100%|██████████| 14000/14000 [02:18<00:00, 101.32img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 70000 images to processed_dataset/real\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying 1 from train: 100%|██████████| 30574/30574 [05:22<00:00, 94.70img/s] \n",
      "Copying 1 from validate: 100%|██████████| 10190/10190 [01:45<00:00, 96.38img/s] \n",
      "Copying 1 from test: 100%|██████████| 10190/10190 [01:45<00:00, 96.62img/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 50954 images to processed_dataset/fake\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "copy_from_folders(dataset1_real, OUTPUT_REAL, prefix=\"d1\")\n",
    "copy_from_folders(dataset1_fake, OUTPUT_FAKE, prefix=\"d1\")\n",
    "\n",
    "copy_from_folders(dataset2_real, OUTPUT_REAL, prefix=\"d2\")\n",
    "copy_from_folders(dataset2_fake, OUTPUT_FAKE, prefix=\"d2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0473f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_REAL = \"processed_dataset/real\"\n",
    "TARGET_FAKE = \"processed_dataset/fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "692a2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(TARGET_REAL, exist_ok=True)\n",
    "os.makedirs(TARGET_FAKE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9fc7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_and_size(folder):\n",
    "    total_size = 0\n",
    "    total_files = 0\n",
    "    for root, _, files in os.walk(folder):\n",
    "        total_files += len(files)\n",
    "        for f in files:\n",
    "            fp = os.path.join(root, f)\n",
    "            if os.path.isfile(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    size_mb = total_size / (1024 * 1024)\n",
    "    size_gb = total_size / (1024 * 1024 * 1024)\n",
    "    return total_files, size_mb, size_gb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cce88484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_dataset/real: 200000 files, 5.70 GB (5834.93 MB)\n",
      "processed_dataset/fake: 120954 files, 3.23 GB (3308.80 MB)\n"
     ]
    }
   ],
   "source": [
    "real_path = \"processed_dataset/real\"\n",
    "fake_path = \"processed_dataset/fake\"\n",
    "real_files, real_mb, real_gb = count_files_and_size(real_path)\n",
    "fake_files, fake_mb, fake_gb = count_files_and_size(fake_path)\n",
    "print(f\"{real_path}: {real_files} files, {real_gb:.2f} GB ({real_mb:.2f} MB)\")\n",
    "print(f\"{fake_path}: {fake_files} files, {fake_gb:.2f} GB ({fake_mb:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac023b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Cawu 4\\AI_Deepfake_Detector_and_Humanizer\\ML_CAWU_4_PROJECT\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_ingestion import *\n",
    "from model_trainer import *\n",
    "from model_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d587715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATASET_PATH = \"processed_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c237c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = prepare_data(dataset_dir=PROCESSED_DATASET_PATH, \n",
    "                                                     batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe8d072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetV2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b88b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|          | 0/7024 [00:00<?, ?it/s]d:\\Cawu 4\\AI_Deepfake_Detector_and_Humanizer\\ML_CAWU_4_PROJECT\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Training Epoch 1: 100%|██████████| 7024/7024 [30:33:37<00:00, 15.66s/it]     \n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss, train_accuracy, val_accuracy = train_model(\n",
    "    model, train_data, val_data, num_epochs=10, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d2be06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_CAWU_4_PROJECT (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
